# Извлечение информации с использованием больших языковых моделей (LLM)

Одна из основных проблем при использовании больших языковых моделей это практически неустранимые галлюцинации, возникающие при ответах на вопросы по загруженным документам. Задача "поговорить со своими документами" возникает очень часто, и как правило, она решается с помощью *промптинга* - вы загружаете вашу статью, договор или другой документ и пишете *промпт*

> «Ответь на вопрос по тексту: ...».

Этот способ работает, но у него есть существенные недостатки: размер документа ограничен 1-3 страницами, непредсказуемое возникновение галлюцинаций - неправильных ответов, выглядящих правдоподобно.

## Что такое RAG

**Retrieval-augmented generation** (далее RAG) дословно переводится как "Генерация с расширенным извлечением" и по сути она частично решает главную проблему языковых моделей - использование для ответов устаревших данных из "весов", что приводит к неправильным ответам. Например, такая проблема часто возникает, когда дать ответ нужно про актуальные события, даты или по некой внешней базе знаний(корпоративной), к которой вообще у модели не могло быть доступа. Основным преимуществом подхода является то, что модель не требуется переобучать на конкретную базу знаний (что может требовать немало времени и значительных вычислительных мощностей).

Подход RAG не новый и существует множество его реализаций - сейчас в основном типичным хорошим решением предлагается нарезать документ на *сниппеты* или *чанки* (кусочки текста, например разделы, абзацы), добавлять их в индекс сгенерировав для них векторные *эмбединги*, с помощью таких библиотек как LangChain, а затем с помощью векторной базы данных искать сниппеты/чанки, в которых могут находиться ответы и с помощью LLM (ChatGPT, GPT-4, локальной модели) генерировать ответ.

Подробнее про использование **RAG** для генерации ответов с опорой на конкретные знания можно почитать в статье [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf) - авторы статьи используют модель комбинируя её с RAG (для извлечения данных используется Wikipedia) т.о. подход сочетает в себе предварительно обученные параметрические и непараметрические механизмы памяти для улучшения доступа к фактическим знаниям и улучшения генерации языка в наукоемких задачах обработки естественного языка.
